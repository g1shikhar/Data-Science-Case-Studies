{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(sqlite:///kinara_assessment_20190807.db)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating sql engine to run sql in jupyter\n",
    "sqlalchemy.create_engine('sqlite:///kinara_assessment_20190807.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting database\n",
    "%sql sqlite:///kinara_assessment_20190807.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///kinara_assessment_20190807.db\n",
      "Done.\n",
      " * sqlite:///kinara_assessment_20190807.db\n",
      "Done.\n",
      " * sqlite:///kinara_assessment_20190807.db\n",
      "Done.\n",
      " * sqlite:///kinara_assessment_20190807.db\n",
      "Done.\n",
      "+----------+\n",
      "| count(*) |\n",
      "+----------+\n",
      "|   2476   |\n",
      "+----------+\n",
      "+----------+\n",
      "| count(*) |\n",
      "+----------+\n",
      "|   2476   |\n",
      "+----------+\n",
      "+----------+\n",
      "| count(*) |\n",
      "+----------+\n",
      "|   2476   |\n",
      "+----------+\n",
      "+----------+\n",
      "| count(*) |\n",
      "+----------+\n",
      "|   2476   |\n",
      "+----------+\n"
     ]
    }
   ],
   "source": [
    "# getting total count of files\n",
    "tot_cnt_ln_inf = %sql select count(*) from loan_information;\n",
    "\n",
    "tot_cnt_ent_Inf =%sql select count(*) from enterprise_information;\n",
    "\n",
    "tot_cnt_score_inf = %sql select count(*) from scores_information;\n",
    "\n",
    "tot_dis_inf = %sql select count(*) from disbursement_information;\n",
    "\n",
    "print(tot_cnt_ln_inf)\n",
    "print(tot_cnt_ent_Inf)\n",
    "print(tot_cnt_score_inf)\n",
    "print(tot_dis_inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///kinara_assessment_20190807.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %sql drop table disbursement_information_nonull;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///kinara_assessment_20190807.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating disbursement files with non null values before join\n",
    "\n",
    "\n",
    "%sql CREATE TABLE disbursement_information_nonull AS SELECT * FROM disbursement_information where account_number IS NOT NULL;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %sql drop table loan_details;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-49dd9f68c92a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-49dd9f68c92a>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    create table loan_details as\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# creating final merged table\n",
    "\n",
    "%%sql >>\n",
    "\n",
    "create table loan_details as\n",
    "select a.loan_id,\n",
    "a.account_number,\n",
    "customer_id,\n",
    "a.enterprise_id,\n",
    "screening_date,\n",
    "product_code,\n",
    "hub_id,\n",
    "business_type,\n",
    "business_activity,\n",
    "business_sector,\n",
    "ManagAgeui_APP,\n",
    "BusinFormalityOfTheBusinessui,\n",
    "ManagCBscoreui_APP,\n",
    "total_disbursement_amount,\n",
    "disbursement_month\n",
    "from loan_information as a\n",
    "left join scores_information as b\n",
    "on a.loan_id = b.loan_id\n",
    "left join enterprise_information as c\n",
    "on a.loan_id= c.loan_id\n",
    "left join disbursement_information_nonull as d\n",
    "on a.account_number = d.account_number;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///kinara_assessment_20190807.db\n",
      "(sqlite3.OperationalError) no such table: loan_details\n",
      "[SQL: select count(*) from loan_details;]\n",
      "(Background on this error at: http://sqlalche.me/e/e3q8)\n"
     ]
    }
   ],
   "source": [
    "# matching the count of final merged table\n",
    "%sql select count(*) from loan_details;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cretaing dataframe from merged table\n",
    "merged_table = %sql select * from loan_details;\n",
    "data =  merged_table.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('C:/Users/gshik/Desktop/Quant Case Study 2019/Kinara_capital/loan_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating label variable using account_number and imputing 0 for total_disbursement_amount  wherver there is null\n",
    "data['target'] = np.where(data['account_number'].isnull(), 0, 1)\n",
    "data['total_disbursement_amount'] = np.where(data['total_disbursement_amount'].isnull(), 0, data['total_disbursement_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating cibil categories using cibil scores\n",
    "data['cibil_category'] = np.where(data['ManagCBscoreui_APP']==-1, 'No info', \n",
    "        (np.where(data['ManagCBscoreui_APP']==0,'LT_6_months',(np.where(data['ManagCBscoreui_APP'] <= 650, 'bad', 'good')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping id's and redundant variables from above step\n",
    "data.drop(['account_number', 'ManagCBscoreui_APP', 'loan_id', 'customer_id', \n",
    "           'enterprise_id', 'disbursement_month', 'screening_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#missing value treatment: replacing the categorical variable with mode and numeric variable with mean\n",
    "categ = list()\n",
    "numeric = list()\n",
    "\n",
    "for c in data.drop(['target'], axis=1).columns:\n",
    "\n",
    "    if data[c].dtype == \"object\":\n",
    "        print(c)\n",
    "        categ.append(c)\n",
    "        data[c].fillna(data[c].mode()[0], inplace = True)\n",
    "    else:\n",
    "        print(c)\n",
    "        numeric.append(c)\n",
    "        data[c].fillna(data[c].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating collateral categories using product_type scores\n",
    "data['collateral'] = np.where(data['product_code'].str[-1]=='U', 'Unsecured', 'Secured')\n",
    "data.drop(['product_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing boxplots for age, though it has oulier according to scatter plot but hey are legitimate age values s no outlier \n",
    "# treatment required\n",
    "data.boxplot(column ='ManagAgeui_APP', grid = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing boxplots for total_disbursement_amount, though it has oulier according to scatter plot but hey are legitimate\n",
    "# total_disbursement_amount values s no outlier treatment required\n",
    "data_disb = data[data['total_disbursement_amount']!=0]\n",
    "data_disb.boxplot(column ='total_disbursement_amount', grid = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution is skewed towards mnufacturing and trading, showing more laon applications from these types\n",
    "data['business_type'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  again distribution is skewed towards particular activities, showing more laon applications from these types\n",
    "data['business_activity'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# distribution is skewed towards cash and non banked people, showing more laon applications from \n",
    "# these people dealing in cash transaction\n",
    "data['BusinFormalityOfTheBusinessui'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most people have good cibil scores\n",
    "data['cibil_category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['collateral'].value_counts().plot(kind='bar', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# since there are lot of categories most of them been skewed, we converte them to binary variables using one - hot encodeing \n",
    "\n",
    "categ.append('hub_id') #since hub id categorical var\n",
    "categ.remove('product_code')#replaced with collateral\n",
    "categ.append('collateral')#replaced with collateral\n",
    "\n",
    "for c in categ:\n",
    "\n",
    "    print(c)\n",
    "\n",
    "    data= pd.get_dummies(data, columns=[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('treated_loan_details.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there lot of variables post one-hot encoding and it is classification problem, xgboost can used as a powerful predictors\n",
    "# capturing non linear rekatonships between independent and dependent variable\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = data.drop(['target', 'total_disbursement_amount'], axis=1)\n",
    "dep = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into train and test datasets for performnace evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(ind, dep, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# following parametrs are bassed on small randomized grid seach\n",
    "Xgb_iter1 = xgb.train({\n",
    "\n",
    "'learning_rate': 0.05,\n",
    "\n",
    "'booster' : 'gbtree',\n",
    "\n",
    "'objective': 'binary:logistic',\n",
    "\n",
    "'max_depth': 1,\n",
    "\n",
    "'min_child_weight':15,\n",
    "\n",
    "'seed' :1,\n",
    "\n",
    "'verbose': True\n",
    "\n",
    "}, dtrain=train, num_boost_round = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_inp_dict = Xgb_iter1.get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# selecting top variables based on gain\n",
    "var_inp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list =[\n",
    "'collateral_Secured',\n",
    " 'BusinFormalityOfTheBusinessui_Cash & Non Banked',\n",
    " 'cibil_category_bad',\n",
    " 'BusinFormalityOfTheBusinessui_Invoice & Banked',\n",
    " 'business_activity_Sales',\n",
    " 'business_activity_Retail',\n",
    " 'business_type_Manufacturing',\n",
    " 'business_sector_Food & Beverage',\n",
    " 'business_sector_Machine  Components',\n",
    " 'business_activity_Whole Sale',\n",
    " 'ManagAgeui_APP',\n",
    " 'business_activity_Job Work',\n",
    " 'business_sector_Textiles',\n",
    " 'cibil_category_LT_6_months',\n",
    " 'business_sector_Fabrication',\n",
    " 'business_sector_Auto Components'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-734961e174ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "test=xgb.DMatrix(X_test, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-2c8f3489429c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# following parametrs are bassed on small randomized grid seach\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m Xgb_iter2 = xgb.train({\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# following parametrs are bassed on small randomized grid seach\n",
    "Xgb_iter2 = xgb.train({\n",
    "\n",
    "'learning_rate': 0.05,\n",
    "\n",
    "'booster' : 'gbtree',\n",
    "\n",
    "'objective': 'binary:logistic',\n",
    "\n",
    "'max_depth': 1,\n",
    "\n",
    "'gamma':0,\n",
    "\n",
    "'min_child_weight':15,\n",
    "\n",
    "'seed' :1,\n",
    "\n",
    "'verbose': True\n",
    "\n",
    "}, dtrain=train, num_boost_round = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate ks\n",
    "def KS_table_10(score, response):\n",
    "\n",
    " \n",
    "\n",
    "    print('getting KS..')\n",
    "\n",
    " \n",
    "\n",
    "    group = 10\n",
    "\n",
    " \n",
    "\n",
    "    df = pd.DataFrame({'score': score, 'response' : response})\n",
    "\n",
    " \n",
    "\n",
    "    df = df.sort_values(by = 'score', ascending = False)\n",
    "\n",
    " \n",
    "\n",
    "    bin_size = len(score)/group\n",
    "\n",
    " \n",
    "\n",
    "    rem = len(score) % group\n",
    "\n",
    " \n",
    "\n",
    "    df['groups'] = list(np.repeat(range(1,rem+1),bin_size + 1)) + list(np.repeat(range(rem+1,11), bin_size))\n",
    "\n",
    " \n",
    "\n",
    "    grouped = df.groupby('groups', as_index =False)\n",
    "\n",
    " \n",
    "\n",
    "    agg = pd.DataFrame({'Total_Obs': grouped.count().response})\n",
    "\n",
    " \n",
    "\n",
    "    agg['No.Res'] = grouped.sum().response\n",
    "\n",
    " \n",
    "\n",
    "    agg['No.Non_Res'] = agg['Total_Obs'] - agg['No.Res']\n",
    "\n",
    " \n",
    "\n",
    "    agg['min_pred'] = grouped.min().score\n",
    "\n",
    " \n",
    "\n",
    "    agg['max_pred'] = grouped.max().score\n",
    "\n",
    " \n",
    "\n",
    "    agg['pred_rr'] = grouped.mean().score\n",
    "\n",
    " \n",
    "\n",
    "    agg['cum_no_res'] = agg['No.Res'].cumsum()\n",
    "\n",
    " \n",
    "\n",
    "    agg['cum_no_non_res'] = agg['No.Non_Res'].cumsum()\n",
    "\n",
    " \n",
    "\n",
    "    agg['percent_cum_res'] = agg['cum_no_res']/agg['cum_no_res'].max()\n",
    "\n",
    "    agg['percent_cum_non_res'] = agg['cum_no_non_res']/agg['cum_no_non_res'].max()\n",
    "\n",
    " \n",
    "\n",
    "    agg['KS'] = agg['percent_cum_res'] - agg['percent_cum_non_res']\n",
    "\n",
    " \n",
    "\n",
    "    return(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xgb_iter2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-53d8f06608ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprob_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mXgb_iter2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mks_dev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKS_table_10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Xgb_iter2' is not defined"
     ]
    }
   ],
   "source": [
    "prob_train= Xgb_iter2.predict(train)\n",
    "\n",
    "ks_dev = KS_table_10(prob_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ks_dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-fbb2db0f2519>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mks_dev\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ks_dev' is not defined"
     ]
    }
   ],
   "source": [
    "ks_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting KS..\n"
     ]
    }
   ],
   "source": [
    "prob_test= Xgb_iter2.predict(test)\n",
    "\n",
    "ks_test = KS_table_10(prob_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total_Obs</th>\n",
       "      <th>No.Res</th>\n",
       "      <th>No.Non_Res</th>\n",
       "      <th>min_pred</th>\n",
       "      <th>max_pred</th>\n",
       "      <th>pred_rr</th>\n",
       "      <th>cum_no_res</th>\n",
       "      <th>cum_no_non_res</th>\n",
       "      <th>percent_cum_res</th>\n",
       "      <th>percent_cum_non_res</th>\n",
       "      <th>KS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.994794</td>\n",
       "      <td>0.977167</td>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>0.176179</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.164414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>2</td>\n",
       "      <td>0.953312</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.960574</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.339673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>59</td>\n",
       "      <td>16</td>\n",
       "      <td>0.749414</td>\n",
       "      <td>0.953007</td>\n",
       "      <td>0.846828</td>\n",
       "      <td>203</td>\n",
       "      <td>22</td>\n",
       "      <td>0.503722</td>\n",
       "      <td>0.064706</td>\n",
       "      <td>0.439016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>55</td>\n",
       "      <td>19</td>\n",
       "      <td>0.549148</td>\n",
       "      <td>0.749414</td>\n",
       "      <td>0.658941</td>\n",
       "      <td>258</td>\n",
       "      <td>41</td>\n",
       "      <td>0.640199</td>\n",
       "      <td>0.120588</td>\n",
       "      <td>0.519610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>0.504527</td>\n",
       "      <td>0.547732</td>\n",
       "      <td>0.520084</td>\n",
       "      <td>297</td>\n",
       "      <td>76</td>\n",
       "      <td>0.736973</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.513443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>0.486853</td>\n",
       "      <td>0.504527</td>\n",
       "      <td>0.491816</td>\n",
       "      <td>329</td>\n",
       "      <td>118</td>\n",
       "      <td>0.816377</td>\n",
       "      <td>0.347059</td>\n",
       "      <td>0.469318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.486853</td>\n",
       "      <td>0.460399</td>\n",
       "      <td>364</td>\n",
       "      <td>157</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.461765</td>\n",
       "      <td>0.441461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>74</td>\n",
       "      <td>29</td>\n",
       "      <td>45</td>\n",
       "      <td>0.320112</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.402964</td>\n",
       "      <td>393</td>\n",
       "      <td>202</td>\n",
       "      <td>0.975186</td>\n",
       "      <td>0.594118</td>\n",
       "      <td>0.381068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.180138</td>\n",
       "      <td>0.320112</td>\n",
       "      <td>0.236536</td>\n",
       "      <td>403</td>\n",
       "      <td>266</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.782353</td>\n",
       "      <td>0.217647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.019289</td>\n",
       "      <td>0.180138</td>\n",
       "      <td>0.080947</td>\n",
       "      <td>403</td>\n",
       "      <td>340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total_Obs  No.Res  No.Non_Res  min_pred  max_pred   pred_rr  cum_no_res  \\\n",
       "0         75      71           4  0.965072  0.994794  0.977167          71   \n",
       "1         75      73           2  0.953312  0.965072  0.960574         144   \n",
       "2         75      59          16  0.749414  0.953007  0.846828         203   \n",
       "3         74      55          19  0.549148  0.749414  0.658941         258   \n",
       "4         74      39          35  0.504527  0.547732  0.520084         297   \n",
       "5         74      32          42  0.486853  0.504527  0.491816         329   \n",
       "6         74      35          39  0.442857  0.486853  0.460399         364   \n",
       "7         74      29          45  0.320112  0.442857  0.402964         393   \n",
       "8         74      10          64  0.180138  0.320112  0.236536         403   \n",
       "9         74       0          74  0.019289  0.180138  0.080947         403   \n",
       "\n",
       "   cum_no_non_res  percent_cum_res  percent_cum_non_res        KS  \n",
       "0               4         0.176179             0.011765  0.164414  \n",
       "1               6         0.357320             0.017647  0.339673  \n",
       "2              22         0.503722             0.064706  0.439016  \n",
       "3              41         0.640199             0.120588  0.519610  \n",
       "4              76         0.736973             0.223529  0.513443  \n",
       "5             118         0.816377             0.347059  0.469318  \n",
       "6             157         0.903226             0.461765  0.441461  \n",
       "7             202         0.975186             0.594118  0.381068  \n",
       "8             266         1.000000             0.782353  0.217647  \n",
       "9             340         1.000000             1.000000  0.000000  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ks on test data is decent and within~1% of dev data showig that model is not overfiiting. ALso we are able to \n",
    "# captue more than 50% rsponders in top 3 deciles\n",
    "\n",
    "ks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.857359\n"
     ]
    }
   ],
   "source": [
    "# Auc values are also >>50% showing significant lift from random\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds =roc_curve(y_train, prob_train)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC curve : 0.849810\n"
     ]
    }
   ],
   "source": [
    "# Auc values are also >>50% showing significant lift from random and within ~1 % from dev showing model is not overfitting\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds =roc_curve(y_test, prob_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"Area under the ROC curve : %f\" % roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the sigmoid function\n",
    "def sigmoid(z):\n",
    "    \n",
    "    # convert input to a numpy array\n",
    "    z = np.array(z)\n",
    "    \n",
    "    # You need to return the following variables correctly \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g=1/(1+np.exp(-z))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1475932ace7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Setup the data matrix appropriately, and add ones for the intercept term of logistic regression in training dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Adding intercept term to training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term of logistic regression in training dataset\n",
    "m, n = X_train.shape\n",
    "\n",
    "# Adding intercept term to training data\n",
    "X = np.concatenate([np.ones((m, 1)), X_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining logloss cost function\n",
    "def computeCostMulti(X, y, theta):\n",
    "       \n",
    "# Computing the cost, using theta as the parameter for logistic regression to fit the data points in X_tain and y_train.\n",
    "    \n",
    "    m = y.shape[0] # number of training examples\n",
    "\n",
    "    J=np.sum(((-y*np.log(sigmoid(np.dot(X,theta))))+(-(1-y)*np.log(1-sigmoid(np.dot(X,theta))))))/m\n",
    "    #print(J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the gradient function to updated weights(theta) with learning rate defined as alpha and iterations defined as \n",
    "# num_iter\n",
    "\n",
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "    \n",
    "    # make a copy of theta, which will be updated by gradient descent\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "       \n",
    "        theta=theta-(alpha*((np.dot(((sigmoid(np.dot(X,theta))-y)),X))/m))\n",
    "        \n",
    "        J_history.append(computeCostMulti(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose some alpha & ierations  - change this for trying different implementaion\n",
    "alpha = 0.001\n",
    "num_iters = 100\n",
    "\n",
    "# init theta and run gradient descent\n",
    "theta = np.zeros(n+1)\n",
    "theta, J_history = gradientDescentMulti(X_train, y_train, theta, alpha, num_iters)\n",
    "\n",
    "# print(theta)\n",
    "# print(\"fbb\",J_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting probablities for test datasets on weights or coeff learned from training data\n",
    "def predict(theta, X):\n",
    "\n",
    "    m = X.shape[0] # Number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly\n",
    "    p = np.zeros(m)\n",
    "\n",
    "    p = sigmoid(np.dot(X, theta))\n",
    "#     print(p)\n",
    "    return p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

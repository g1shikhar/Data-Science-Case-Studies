{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gshik\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\gshik\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "C:\\Users\\gshik\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('data/Train.csv', index_col=0)\n",
    "Test = pd.read_csv('data/Test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train =Train['is_returning_customer']\n",
    "X_train = Train.drop(['customer_id', 'is_returning_customer'],axis = 1)\n",
    "\n",
    "Y_test =Test['is_returning_customer']\n",
    "X_test = Test.drop(['customer_id', 'is_returning_customer'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Strong> Why Random Forest and GBM? </Strong>\n",
    "\n",
    "1. The problem in hand is <Strong> Supervised Binary Calssification Problem </Strong>. Some of the state of art Classification Algorithms are:<br>\n",
    "    1.1 SVM<br>\n",
    "    1.2 Random Forest<br>\n",
    "    1.3 GBM<br>\n",
    "    1.4 XGB<br>\n",
    "Given enough data and features all of these algorithms have been proved to perform better than Traditional Statistical Algorithms like Logistic and Naive Bayes.\n",
    "\n",
    "\n",
    "2. Among these apart from SVM which is based on the results of single classifier, all the other 3 are ensemble algorithms making predictions based on the results of several classifiers and generally outperform a single classifier.\n",
    "\n",
    "\n",
    "3. Random Forest is bagging algorithm and makes prediction based on unweighted samples whereas GBM & XGB are boosting algorithms that re-evaulates sample weights based on misclassification. Also all the trees in RF are independent and unweighted whereas in boosting all the trees are dependent on the prior trees and are weighted. \n",
    "\n",
    "\n",
    "4. Thus though RF can help to reduce Variance, Boosting reduces both Variance and Bias but however is more prone to overfitting due to continuos weight adjustment(can lead to extremly high weights for few samples which are actually noise)\n",
    "\n",
    "\n",
    "\n",
    "5. It thus make sense to test the results across train and test set using any of the <strong> Bagging Algorithms (Random Forest in our case) </strong> and one of the <strong> Boosting Algorithms(GBM in our case)</strong>  and compare their Performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized grid Search for Random Forest  and GBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup the hyperparameter grid\n",
    "param_dist = {\n",
    "    'bootstrap': [True],\n",
    "    'n_estimators': [100,200,300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_leaf': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'random_state':[11]\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiate the grid search model for Random Forest Classifier\n",
    "randomized_search_rfc = RandomizedSearchCV(estimator = rfc, param_distributions = param_dist, \n",
    "                          n_iter=20, cv = 3, random_state=11)\n",
    "\n",
    "# Fit it to the data\n",
    "randomized_search_rfc.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# setup the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100,200,300],\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'min_samples_leaf': [10, 20, 30],\n",
    "    'min_samples_split': [5, 10, 20],\n",
    "    'random_state':[11]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model for Gradien Boosting Classifier\n",
    "randomized_search_gbc = RandomizedSearchCV(estimator = gbc, param_distributions= param_dist, \n",
    "                          n_iter = 20, cv = 3, random_state=11)\n",
    "\n",
    "\n",
    "# Fit it to the data\n",
    "randomized_search_gbc.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"----------- Best Parametrs for Random Forest Model are:-------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(randomized_search_rfc.best_params_)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------- Accuracy Score for above Random Forest classifier on Train Data:-------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(randomized_search_rfc.best_score_)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------- Best Parametrs for Gradient Boosting Model are:-------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(randomized_search_gbc.best_params_)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------- Accuracy Score for above Gradient Boosting classifier on Train Data:-------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(randomized_search_gbc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Parameters from Grid Search:\n",
    "<br>\n",
    "<strong> Best Parametrs for Random Forest Model are:</strong>\n",
    "<br>\n",
    "{'random_state': 11, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 20, 'max_depth': 7, 'bootstrap': True}\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Accuracy Score for above Random Forest classifier on Train Data:\n",
    "<br>\n",
    "\n",
    "0.8316522741151166\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<strong> Best Parametrs for Gradient Boosting Model are:</strong>\n",
    "<br>\n",
    "\n",
    "{'random_state': 11, 'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 30, 'max_depth': 3}\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "Accuracy Score for above Gradient Boosting classifier on Train Data:\n",
    "<br>\n",
    "\n",
    "0.8346321905872971"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------- Training the two models on the Best Paramters from Grid Search-------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------- Getting Predictions from Models-------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------- Model Performance on Validation Set-------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------- Performance Comaprision across Train and Test for RF and GBM-------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF_train</th>\n",
       "      <th>RF_test</th>\n",
       "      <th>GBM_train</th>\n",
       "      <th>GBM_test</th>\n",
       "      <th>%diff_RF</th>\n",
       "      <th>%diff_GBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>0.407669</td>\n",
       "      <td>0.408919</td>\n",
       "      <td>0.403234</td>\n",
       "      <td>0.404763</td>\n",
       "      <td>-0.306443</td>\n",
       "      <td>-0.379205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.833806</td>\n",
       "      <td>0.832786</td>\n",
       "      <td>0.837403</td>\n",
       "      <td>0.836167</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.147539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_Score</th>\n",
       "      <td>0.505327</td>\n",
       "      <td>0.500426</td>\n",
       "      <td>0.538727</td>\n",
       "      <td>0.534568</td>\n",
       "      <td>0.969860</td>\n",
       "      <td>0.772021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          RF_train   RF_test GBM_train  GBM_test  %diff_RF %diff_GBM\n",
       "RMSE      0.407669  0.408919  0.403234  0.404763 -0.306443 -0.379205\n",
       "Accuracy  0.833806  0.832786  0.837403  0.836167  0.122348  0.147539\n",
       "F1_Score  0.505327  0.500426  0.538727  0.534568  0.969860  0.772021"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"----------- Training the two models on the Best Paramters from Grid Search-------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "gbc = GradientBoostingClassifier(random_state= 11, n_estimators= 300, min_samples_split= 5,\\\n",
    "                                 min_samples_leaf= 30, max_depth= 3)\n",
    "rfc = RandomForestClassifier(random_state= 11, n_estimators= 100, min_samples_split=10,\\\n",
    "                                    min_samples_leaf= 20, max_depth= 7, bootstrap=True)\n",
    "\n",
    "gbc.fit(X_train, Y_train)\n",
    "rfc.fit(X_train, Y_train)\n",
    "                             \n",
    "print(\"\\n\")\n",
    "print(\"----------- Getting Predictions from Models-------------\")\n",
    "print(\"\\n\")\n",
    "gbc_class = gbc.predict(X_test)\n",
    "gbc_prob = gbc.predict_proba(X_test)\n",
    "gbc_prob = pd.DataFrame(gbc_prob, columns = ['Prob_0','Prob_1'])\n",
    "gbc_class2 = gbc.predict(X_train)\n",
    "gbc_prob2 = gbc.predict_proba(X_train)\n",
    "gbc_prob2 = pd.DataFrame(gbc_prob2, columns = ['Prob_0','Prob_1'])\n",
    "\n",
    "rfc_class = rfc.predict(X_test)\n",
    "rfc_prob = rfc.predict_proba(X_test)\n",
    "rfc_prob = pd.DataFrame(rfc_prob, columns = ['Prob_0','Prob_1'])\n",
    "rfc_class2 = rfc.predict(X_train)\n",
    "rfc_prob2 = rfc.predict_proba(X_train)\n",
    "rfc_prob2 = pd.DataFrame(rfc_prob2, columns = ['Prob_0','Prob_1'])\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------- Model Performance on Validation Set-------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "Performnace_DF = pd.DataFrame(columns = [\"RF_train\", \"RF_test\", \"GBM_train\", \"GBM_test\"],\\\n",
    "             index = [\"RMSE\", \"Accuracy\", \"F1_Score\"])\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, gbc_class))\n",
    "rmse2 = np.sqrt(mean_squared_error(Y_train, gbc_class2))\n",
    "Performnace_DF.loc[\"RMSE\", \"GBM_test\"]=rmse\n",
    "Performnace_DF.loc[\"RMSE\", \"GBM_train\"]=rmse2\n",
    "\n",
    "accuracy = accuracy_score(Y_test, gbc_class)\n",
    "accuracy2 = accuracy_score(Y_train, gbc_class2)\n",
    "Performnace_DF.loc[\"Accuracy\", \"GBM_test\"]=accuracy\n",
    "Performnace_DF.loc[\"Accuracy\", \"GBM_train\"]=accuracy2\n",
    "\n",
    "F1_Score = f1_score(Y_test, gbc_class)\n",
    "F1_Score2 = f1_score(Y_train, gbc_class2)\n",
    "Performnace_DF.loc[\"F1_Score\", \"GBM_test\"]=F1_Score\n",
    "Performnace_DF.loc[\"F1_Score\", \"GBM_train\"]=F1_Score2\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, rfc_class))\n",
    "rmse2 = np.sqrt(mean_squared_error(Y_train, rfc_class2))\n",
    "Performnace_DF.loc[\"RMSE\", \"RF_test\"]=rmse\n",
    "Performnace_DF.loc[\"RMSE\", \"RF_train\"]=rmse2\n",
    "\n",
    "accuracy = accuracy_score(Y_test, rfc_class)\n",
    "accuracy2 = accuracy_score(Y_train, rfc_class2)\n",
    "Performnace_DF.loc[\"Accuracy\", \"RF_test\"]=accuracy\n",
    "Performnace_DF.loc[\"Accuracy\", \"RF_train\"]=accuracy2\n",
    "\n",
    "F1_Score = f1_score(Y_test, rfc_class)\n",
    "F1_Score2 = f1_score(Y_train, rfc_class2)\n",
    "Performnace_DF.loc[\"F1_Score\", \"RF_test\"]=F1_Score\n",
    "Performnace_DF.loc[\"F1_Score\", \"RF_train\"]=F1_Score2\n",
    "\n",
    "Performnace_DF['%diff_RF'] = (Performnace_DF.RF_train-Performnace_DF.RF_test)\\\n",
    "*100/Performnace_DF.RF_train\n",
    "Performnace_DF['%diff_GBM'] = (Performnace_DF.GBM_train-Performnace_DF.GBM_test)\\\n",
    "*100/Performnace_DF.GBM_train\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------- Performance Comaprision across Train and Test for RF and GBM-------------\")\n",
    "print(\"\\n\")\n",
    "Performnace_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations from the Performance Results:\n",
    "\n",
    "1. GBM performs better than RF on validation set on all parameters whether it is RMSE, Accuracy or F1 score\n",
    "    \n",
    "\n",
    "2. Moreover neither of the model is overfitting as can been seen from the % diff_RF/ % diff_GBM due to regularization.\n",
    "    \n",
    "<strong> Therefore we can conclude that GBM is better model than the RF </Strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting KS..\n",
      "\n",
      "\n",
      "KS for GBM is:  0.4875215379894331\n",
      "67.76078053481089 % of responders are captured in top 3 Deciles for with GBM.\n",
      "\n",
      "\n",
      "getting KS..\n",
      "\n",
      "\n",
      "KS for Random Forest is:  0.472980330576563\n",
      "66.634545892556 % of responders are captured in top 3 Deciles for with Random Forest.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------- GBM is better even in terms of KS and Capture rate on validation set.-------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function to calculate ks and Capture Rate \n",
    "\n",
    "def KS_table_10(score, response):\n",
    "    print('getting KS..')\n",
    "    group = 10\n",
    "    df = pd.DataFrame({'score': score, 'response' : response})\n",
    "    df = df.sort_values(by = 'score', ascending = False)\n",
    "    bin_size = len(score)/group\n",
    "    rem = len(score) % group\n",
    "    df['groups'] = list(np.repeat(range(1,rem+1),bin_size + 1)) + list(np.repeat(range(rem+1,11), bin_size))\n",
    "    grouped = df.groupby('groups', as_index =False)\n",
    "    agg = pd.DataFrame({'Total_Obs': grouped.count().response})\n",
    "    agg['No.Res'] = grouped.sum().response\n",
    "    agg['No.Non_Res'] = agg['Total_Obs'] - agg['No.Res']\n",
    "    agg['min_pred'] = grouped.min().score\n",
    "    agg['max_pred'] = grouped.max().score\n",
    "    agg['pred_rr'] = grouped.mean().score\n",
    "    agg['cum_no_res'] = agg['No.Res'].cumsum()\n",
    "    agg['cum_no_non_res'] = agg['No.Non_Res'].cumsum()\n",
    "    agg['percent_cum_res'] = agg['cum_no_res']/agg['cum_no_res'].max()\n",
    "    agg['percent_cum_non_res'] = agg['cum_no_non_res']/agg['cum_no_non_res'].max()\n",
    "    agg['KS'] = agg['percent_cum_res'] - agg['percent_cum_non_res']\n",
    "    max_ks = agg['KS'].max()\n",
    "    return(agg, max_ks)\n",
    "\n",
    "Decile, KS = KS_table_10(gbc_prob['Prob_1'], Y_test)\n",
    "print(\"\\n\")\n",
    "print('KS for GBM is: ', KS)\n",
    "print(Decile['percent_cum_res'][2]*100, '% of responders are captured in top 3 Deciles for with GBM.')\n",
    "print(\"\\n\")\n",
    "\n",
    "Decile, KS = KS_table_10(rfc_prob['Prob_1'], Y_test)\n",
    "print(\"\\n\")\n",
    "print('KS for Random Forest is: ', KS)\n",
    "print(Decile['percent_cum_res'][2]*100, '% of responders are captured in top 3 Deciles for with Random Forest.')\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"----------- GBM is better even in terms of KS and Capture rate on validation set.-------------\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------- Saving Final Model Files-------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/RF_Classifer.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"----------- Saving Final Model Files-------------\")\n",
    "print(\"\\n\")\n",
    "\n",
    "joblib.dump(gbc,'model/GBM_Classifer.joblib')\n",
    "joblib.dump(rfc,'model/RF_Classifer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
